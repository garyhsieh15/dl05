{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+ZCuBQKhYSnBN2ni/RdlO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garyhsieh15/dl05/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q430iO0Fqe4m",
        "outputId": "a5278c49-894b-42fb-b8ad-4c13c04dacc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9qKiYgGtL3E",
        "outputId": "07a98651-20aa-4cf6-ea18-d3868e909977"
      },
      "source": [
        "%cd /content/drive/MyDrive/work/NCKU/10902/dl/HW05/dl05/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/work/NCKU/10902/dl/HW05/dl05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRNulbktuAQq",
        "outputId": "b7ddad04-105f-496a-e115-e84a7899ad2f"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/work/NCKU/10902/dl/HW05/dl05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "T0gxHb8FudMS",
        "outputId": "356cb417-910f-4970-fa5f-16f537dbf955"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from load_data import CreateList, CustomDataset\n",
        "from models import LeNet5, VGG\n",
        "from utils import updateBN, savemodel, Log\n",
        "\n",
        "trial_info = 'lenet_init'\n",
        "log = Log(trial_info)\n",
        "\n",
        "first = 1e-4\n",
        "last  = 1e-4\n",
        "#%% All parameters setting\n",
        "para = {\n",
        "    # Dataset\n",
        "    'dataset': 'aoi',\n",
        "    'batch_size': 48,\n",
        "    'split': 0.8,  # ratio of training data\n",
        "    # Model\n",
        "    'resume': '',  # a path of trained model\n",
        "    'pruned': '',  # a path of pruned model\n",
        "    'pretrain': False,\n",
        "    'cfg': [],  # None or a list of integers and 'M'\n",
        "    # Training\n",
        "    'cuda': True, # True\n",
        "    'workers': 0,\n",
        "    'epochs': 100,\n",
        "    'checkpoint_freq': 5,\n",
        "    'early_stop': False,\n",
        "    # Hyperparameters\n",
        "    'lr': 1e-2,\n",
        "    'decay': 1e-5,\n",
        "    'channel_sparsity': True,  #Ture whether adding L1-norm of BN gamma factor\n",
        "    'sparsity_rate': 0,\n",
        "    'patience': 8,\n",
        "    # Trial id\n",
        "    'trial': trial_info}\n",
        "\n",
        "log.log('Parameters Setting:\\n{}'.format(para).replace(', ', ',\\n '))\n",
        "\n",
        "#%% Prepare data pipeline\n",
        "#dir_img_train = 'C:/Dataset/AOI/train_images/'\n",
        "dir_img_train = './aoi/train_images/'\n",
        "#path_label_train = 'C:/Dataset/AOI/train.csv'\n",
        "path_label_train = './aoi/train.csv'\n",
        "\n",
        "# Split image list and label list into train and valid.\n",
        "train_list = CreateList(dir_img_train, path_label_train, shuffle=True)\n",
        "train_valid_split = round(train_list.length * para['split'])\n",
        "train_img = train_list.img[:train_valid_split]\n",
        "train_label = train_list.label[:train_valid_split]\n",
        "valid_img = train_list.img[train_valid_split:]\n",
        "valid_label = train_list.label[train_valid_split:]\n",
        "\n",
        "# Image preprocessing\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "}\n",
        "\n",
        "log.log('Data Preprocessing:\\n{}'.format(transform))\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = CustomDataset(train_img,\n",
        "                                train_label,\n",
        "                                transform['train'])\n",
        "valid_dataset = CustomDataset(valid_img,\n",
        "                                valid_label,\n",
        "                                transform['valid'])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                        batch_size=para['batch_size'],\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=para['workers'],\n",
        "                                        pin_memory=True)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                        batch_size=para['batch_size'],\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=para['workers'],\n",
        "                                        pin_memory=True)\n",
        "\n",
        "#%% Build a model\n",
        "#net = VGG(dataset=para['dataset'], pretrained=para['pretrain'])\n",
        "net = LeNet5('aoi')\n",
        "\n",
        "# Send model into gpu memory\n",
        "if para['cuda']:\n",
        "    net.cuda()\n",
        "\n",
        "log.log('Model Structure:\\n{}'.format(net))\n",
        "\n",
        "#%% Create loss function, optimzier and training scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(),\n",
        "                    lr=para['lr'],\n",
        "                    weight_decay=para['decay'],\n",
        "                    momentum=0.9,\n",
        "                    nesterov=True)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
        "                                                       factor=0.1, patience=para['patience'], verbose=True, threshold=1e-4, min_lr=1e-6)\n",
        "\n",
        "log.log('Optimizer:\\n{}'.format(optimizer))\n",
        "\n",
        "#%% Train the Model\n",
        "start_epoch = 0\n",
        "best_prec1 = 0\n",
        "if __name__ == '__main__':\n",
        "    start_training = time.time()\n",
        "    log.log('Start training model...')\n",
        "\n",
        "    for epoch in range(start_epoch, start_epoch + para['epochs']):\n",
        "        # loss list\n",
        "        list_loss_train = []\n",
        "        list_loss_valid = []\n",
        "        # training\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        net.train()  # activate autograd\n",
        "        for i, (images, label) in enumerate(train_loader):\n",
        "            if para['cuda']:\n",
        "                images, label = images.cuda(), label.cuda()\n",
        "            \n",
        "            optimizer.zero_grad()  # clear buffer\n",
        "            out = net(images) \n",
        "            train_loss = criterion(out, label)\n",
        "            train_loss.backward()  \n",
        "            # subgradient decent\n",
        "            if para['channel_sparsity']:\n",
        "                updateBN(net, para['sparsity_rate'], False, first, last)\n",
        "            optimizer.step()  # update weights\n",
        "            \n",
        "            _, pred = torch.max(out.data, 1)  # max() return maximum and its index in each row\n",
        "            train_total += float(label.size(0))\n",
        "            train_correct += float((pred == label).sum())\n",
        "            \n",
        "        # validation\n",
        "        valid_correct = 0\n",
        "        valid_total = 0\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, label in valid_loader:\n",
        "                if para['cuda']:\n",
        "                    images, label = images.cuda(), label.cuda()\n",
        "                \n",
        "                out = net(images)  # forward\n",
        "                valid_loss = criterion(out, label)\n",
        "                _, pred = torch.max(out.data, 1)  # max() return maximum and its index in each row\n",
        "                valid_total += float(label.size(0))\n",
        "                valid_correct += float((pred == label).sum())\n",
        "\n",
        "        # metrics\n",
        "        train_acc = 100*train_correct / train_total\n",
        "        valid_acc = 100*valid_correct / valid_total\n",
        "        is_best = valid_acc > best_prec1\n",
        "        best_prec1 = max(valid_acc, best_prec1)\n",
        "        list_loss_train.append(train_loss)\n",
        "        list_loss_valid.append(valid_loss)\n",
        "\n",
        "        scheduler.step(valid_acc)\n",
        "        \n",
        "        # save model\n",
        "        state = {\n",
        "            'epoch': epoch,  # last epoch\n",
        "            'state_dict': net.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict()\n",
        "            }\n",
        "        state.update(para)\n",
        "        suffix = para['trial']\n",
        "        # save pruned structure\n",
        "        if para['pruned']:\n",
        "            state['cfg'] = pruned_pkl['cfg']\n",
        "            suffix += '_' + args.pruned.split('_')[-1][:-4]\n",
        "\n",
        "        save = savemodel(state, is_best, para['checkpoint_freq'], suffix, False)\n",
        "        if save:\n",
        "            log.log(save)\n",
        "\n",
        "        # print result\n",
        "        if (epoch+1) % 1 == 0:\n",
        "\n",
        "            log.log('Epoch:{}/{}\\nAccuracy(Train/Valid):{:.02f}/{:.02f}% Loss(Train/Valid):{:.3f}/{:.3f}'.format(\n",
        "                epoch, start_epoch + para['epochs']-1, train_acc, valid_acc, train_loss, valid_loss))\n",
        "\n",
        "        # early stopping\n",
        "        if para['early_stop'] and valid_acc > 99.5:\n",
        "            log.log('Early stop beacause valid accuracy > 99.5.')\n",
        "            break\n",
        "        \n",
        "    end_training = time.time()\n",
        "    #log.log('Time:', round((end_training - start_training)/60, 2), 'mins')\n",
        "    log.log('Time:{}  mins'.format(round((end_training - start_training)/60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ae973ae73696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# Send model into gpu memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Structure:\\n{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skt1FrQxmq5B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}